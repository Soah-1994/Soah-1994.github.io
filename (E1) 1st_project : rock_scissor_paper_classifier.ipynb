{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 로딩하기\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오는 함수 만들기 : 양창원님의 코드를 인용함\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    \n",
    "    number_of_data = 0 \n",
    "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
    "        number_of_data += 1\n",
    "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
    "        number_of_data += 1\n",
    "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
    "        number_of_data += 1\n",
    "    # 위 반복문을 실행하면 전체 이미지 파일 개수를 알 수 있다. \n",
    "    \n",
    "    img_size = 28\n",
    "    color    = 3\n",
    "    \n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs   = np.zeros(number_of_data * img_size * img_size * color, dtype = np.int32).reshape(number_of_data, img_size, img_size,color)\n",
    "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
    "\n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
    "        img             = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]     = 0      # 가위 : 0\n",
    "        idx             = idx + 1\n",
    "\n",
    "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
    "        img             = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]     = 1      # 바위 : 1\n",
    "        idx             = idx + 1       \n",
    "    \n",
    "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
    "        img             = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]     = 2      # 보 : 2\n",
    "        idx             = idx + 1\n",
    "        \n",
    "    print(\"이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터는 Slack에 양창원님께서 올려주신 15000개의 데이터를 사용했다.\n",
    "# 트레이닝 데이터 : 14700개, 테스트 데이터 : 300개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 개수는 14700 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터 불러오기\n",
    "image_dir_path     = os.getenv(\"HOME\") + \"/aiffel/dataset/*\"\n",
    "(x_train, y_train) = load_data(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "# test데이터 불러오기\n",
    "image_dir_path     = os.getenv(\"HOME\") + \"/aiffel/data4\"\n",
    "(x_test, y_test)   = load_data(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화하기\n",
    "x_train_normal       = x_train / 255.0\n",
    "x_test_normal        = x_test  / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 0.8196078431372549\n"
     ]
    }
   ],
   "source": [
    "# 정규화 확인하기 : 0 ~ 1 사이의 값을 가져야 함\n",
    "print(np.min(x_train_normal), np.max(x_train_normal))   # 훈련 데이터\n",
    "print(np.min(x_test_normal), np.max(x_test_normal))     # test 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14700, 28, 28, 3)\n",
      "(14700,)\n",
      "(300, 28, 28, 3)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# 불러온 데이터 shape 확인하기\n",
    "# (데이터 갯수, 가로, 세로, 깊이(색깔이 흑백이면 1, 컬러면 RGB를 뜻하는 3)\n",
    "\n",
    "# 훈련 데이터\n",
    "print(x_train_normal.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# test 데이터\n",
    "print(x_test_normal.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_156 (Conv2D)          (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_156 (MaxPoolin (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_157 (MaxPoolin (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_158 (MaxPoolin (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_159 (MaxPoolin (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 327,747\n",
      "Trainable params: 327,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 만들기\n",
    "\n",
    "# 모델 생성\n",
    "tf_model = tf.keras.Sequential()\n",
    "# 계층 1\n",
    "tf_model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), input_shape = (28, 28, 3), activation = \"relu\"))\n",
    "tf_model.add(tf.keras.layers.MaxPooling2D(pool_size = (1, 1)))\n",
    "tf_model.add(tf.keras.layers.Dropout(0.3))\n",
    "# 계층 2\n",
    "tf_model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "tf_model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "tf_model.add(tf.keras.layers.Dropout(0.3))\n",
    "# 계층 3\n",
    "tf_model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "tf_model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "tf_model.add(tf.keras.layers.Dropout(0.3))\n",
    "# 계층 4\n",
    "tf_model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "tf_model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "tf_model.add(tf.keras.layers.Dropout(0.3))\n",
    "# 계층 5\n",
    "tf_model.add(tf.keras.layers.Flatten())\n",
    "tf_model.add(tf.keras.layers.Dropout(0.3))\n",
    "tf_model.add(tf.keras.layers.Dense(units = 512, activation = \"relu\"))\n",
    "tf_model.add(tf.keras.layers.Dense(units = 3, activation = \"softmax\"))\n",
    "\n",
    "# 모델 확인하기\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Loss, Optimizer, Metrics 설정하기\n",
    "tf_model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(lr = 0.001), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 1.0982 - accuracy: 0.3422\n",
      "Epoch 2/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.9726 - accuracy: 0.4978\n",
      "Epoch 3/15\n",
      "460/460 [==============================] - 1s 3ms/step - loss: 0.7222 - accuracy: 0.6812\n",
      "Epoch 4/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.5564 - accuracy: 0.7638\n",
      "Epoch 5/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.4477 - accuracy: 0.8142\n",
      "Epoch 6/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.3917 - accuracy: 0.8439\n",
      "Epoch 7/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.3472 - accuracy: 0.8639\n",
      "Epoch 8/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.3180 - accuracy: 0.8731\n",
      "Epoch 9/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.2827 - accuracy: 0.8867\n",
      "Epoch 10/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.2767 - accuracy: 0.8936\n",
      "Epoch 11/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.2458 - accuracy: 0.9071\n",
      "Epoch 12/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.2385 - accuracy: 0.9077\n",
      "Epoch 13/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.2175 - accuracy: 0.9165\n",
      "Epoch 14/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.2098 - accuracy: 0.9207\n",
      "Epoch 15/15\n",
      "460/460 [==============================] - 2s 3ms/step - loss: 0.2003 - accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련하기\n",
    "hostory = tf_model.fit(x_train_normal, y_train, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험하기 : accuracy가 0.6 이상이 나와야 함.\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test)\n",
    "# 점수가 제일 좋게 나온 data폴더를 test 데이터로 사용하였음.\n",
    "# 총 19개 폴더(각 폴더당 사진은 300개)의 결과는 아래에 실어놓음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 어려웠던 점 및 모호한 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 모델은 잘 학습되나 test 데이터가 바뀔 때 마다 결과가 상이함(최고 100%, 최소 31.6%)\n",
    "#### - test 데이터가 바뀔때 마다 결과가 다른 이유는 눈으로 봐서는 잘 모르겠음\n",
    "#### - 19개 중 15개가 60%를 넘긴것으로 보아 추측컨데 나머지 4개의 데이터 셋은 트레이닝 셋과 많이 다른 것으로 생각됨\n",
    "#### - 그 차이는 눈으로 보고 추측하기로는 손과 나머지 배경의 경계가 뚜렷하게 나온 사진들을 더 잘 분류하는것으로 생각함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 루브릭 평가를 위해 시도한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 좋은 건지 모르겠으나 최대한 계층을 많이 넣었음.\n",
    "#### - 학습을 100번 시켜보고 어느 횟수가 적당한지 본 다음 다시 모델을 만들어서 학습 시킴(그 결과 실전에서는 15번 학습시킴)\n",
    "#### - 오버피팅 되는것을 방지하기 위해 pooling과 dropout을 해줌. kernel_initializer란 것도 있던거 같으나 이해하지 못해서 안 씀."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 아쉬운 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 아직 코드를 보고 어떤 것이 어떤 원리로 작동하는지 알지 못해서 내 코딩이 어디가 부족한지 찾지 못함\n",
    "#### - 구글링을 해도 무슨말을 하는것인지 모르겠으며, 어떤 것은 나보다 계층이 적은데도 잘 되었다는 블로그가 있어서 더 아쉬움\n",
    "#### - 아직 오버피팅을 피하는 방법을 제대로 몰라서 학습횟수와 계층 수와 드랍아웃으로만 조절한 것 같아서 오버피팅 여부를 확신할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 궁금증을 해결하기 위해 19개의 폴더들을 각각 전부 test 데이터로 설정해서 돌려봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 당연하겠지만 test 데이터로 뽑힌 폴더는 상위폴더에서 빼내어 다른곳에 넣고 트레이닝 데이터에 포함되지 않게 함\n",
    "#### - 때문에 데이터 불러오기, 정규화, 모델 생성, 학습, 결과보기를 총 20번 함\n",
    "#### - 결과는 흥미롭지만 왜 차이가 나는지는 모르겠음\n",
    "#### - 19개중 15개가 0.6을 넘은것으로 보아 데이터문제라고 말하고 싶은것이 사실임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 시험하기 : accuracy가 0.6 이상이 나와야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4793 - accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "# data1을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2303 - accuracy: 0.6267\n"
     ]
    }
   ],
   "source": [
    "# data2을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# data3을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# data4을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.3790 - accuracy: 0.5867\n"
     ]
    }
   ],
   "source": [
    "# data5을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8467\n"
     ]
    }
   ],
   "source": [
    "# data6을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "# data7을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2453 - accuracy: 0.3167\n"
     ]
    }
   ],
   "source": [
    "# data8을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "# data9을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# data10을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8767\n"
     ]
    }
   ],
   "source": [
    "# data11을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0664 - accuracy: 0.6767\n"
     ]
    }
   ],
   "source": [
    "# data12을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5280 - accuracy: 0.6967\n"
     ]
    }
   ],
   "source": [
    "# data13을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7829 - accuracy: 0.6633\n"
     ]
    }
   ],
   "source": [
    "# data14을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1793 - accuracy: 0.6467\n"
     ]
    }
   ],
   "source": [
    "# data15을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9208 - accuracy: 0.5667\n"
     ]
    }
   ],
   "source": [
    "# data16을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "# data17을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.8700\n"
     ]
    }
   ],
   "source": [
    "# data18을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "# data19을 test데이터로 한 경우\n",
    "evaluation1 = tf_model.evaluate(x_test_normal, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
